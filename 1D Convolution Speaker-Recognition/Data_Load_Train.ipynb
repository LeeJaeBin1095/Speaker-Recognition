{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7df0570",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting silence_remover\n",
      "  Using cached silence_remover-1.0.0-py3-none-any.whl (7.9 kB)\n",
      "Installing collected packages: silence-remover\n",
      "Successfully installed silence-remover-1.0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ensorflow-gpu (c:\\users\\thakd\\appdata\\roaming\\python\\python37\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-gpu (c:\\users\\thakd\\appdata\\roaming\\python\\python37\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-gpu (c:\\users\\thakd\\appdata\\roaming\\python\\python37\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-gpu (c:\\users\\thakd\\appdata\\roaming\\python\\python37\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-gpu (c:\\users\\thakd\\appdata\\roaming\\python\\python37\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-gpu (c:\\users\\thakd\\appdata\\roaming\\python\\python37\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install silence_remover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6745b023",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thakd\\AppData\\Roaming\\Python\\Python37\\site-packages\\numpy\\_distributor_init.py:32: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\thakd\\AppData\\Roaming\\Python\\Python37\\site-packages\\numpy\\.libs\\libopenblas.GK7GX5KEQ4F6UYO3P26ULGBQYHGQO7J4.gfortran-win_amd64.dll\n",
      "C:\\Users\\thakd\\AppData\\Roaming\\Python\\Python37\\site-packages\\numpy\\.libs\\libopenblas.WCDJNK7YVMPZQ2ME2ZZHJJRJ3JIKNDB7.gfortran-win_amd64.dll\n",
      "  stacklevel=1)\n",
      "C:\\Users\\thakd\\anaconda3\\envs\\UI\\lib\\site-packages\\pydub\\utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import shutil\n",
    "import csv\n",
    "import os\n",
    "import librosa\n",
    "import librosa.display\n",
    "import pyaudio\n",
    "import wave\n",
    "import keras\n",
    "import pyaudio  \n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import speech_recognition as speech_r\n",
    "import scipy.signal as signal\n",
    "import random as rn\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from pydub import AudioSegment\n",
    "from time import sleep\n",
    "from matplotlib import cm\n",
    "from python_speech_features import logfbank, fbank\n",
    "from scipy.fftpack import dct\n",
    "from silence_remover.silence_detector import SilenceDetector\n",
    "from silence_remover.filter_generator import FilterGenerator\n",
    "from silence_remover.media_editor import MediaEditor\n",
    "from scipy.io import wavfile\n",
    "from collections import defaultdict, Counter\n",
    "from scipy import signal\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from keras.layers import Dense\n",
    "from keras import Input\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Dropout, Conv1D, GlobalMaxPooling1D, Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.models import load_model, Model\n",
    "from keras.layers import Dense,concatenate, TimeDistributed, Dropout, Bidirectional, GRU, BatchNormalization, Activation, LeakyReLU, LSTM, Flatten, RepeatVector, Permute, MaxPooling1D,Multiply,Conv1D, Conv2D, MaxPooling2D\n",
    "from playsound import playsound\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0406f0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"./train_mfcc/\"\n",
    "X_train = [] \n",
    "X_test = []\n",
    "Y_train = []\n",
    "Y_test = []\n",
    "tf_classes = 0\n",
    "labels = []\n",
    "X_data = []\n",
    "Y_label = []\n",
    "\n",
    "    \n",
    "def load_npy(save_path) : \n",
    "    \n",
    "    # 데이터들을 저장할 배열\n",
    "    \n",
    "    global X_train, X_test, Y_train, Y_test, tf_classes\n",
    "    \n",
    "    folders = os.listdir(save_path) ## 경로에 있는 폭더 목록\n",
    "    \n",
    "    for folder in folders :\n",
    "        \n",
    "        if not os.path.isdir(save_path) : continue \n",
    "            \n",
    "        files = os.listdir(save_path + \"/\" + folder)        \n",
    "        print(\"Foldername : \", folder, \"-\", len(files),\"파일\")\n",
    "        \n",
    "        for file in files:\n",
    "            if not file.endswith(\".npy\") : continue ## 미리 전처리하여 변환한 npy불러오기\n",
    "            \n",
    "            else:               \n",
    "                mfcc = np.load(save_path + \"/\" + folder + \"/\" + file) ## mfcc변환한 파일 값 저장\n",
    "                X_data.extend(mfcc)\n",
    "                \n",
    "                label = [0 for i in range(len(folders))]\n",
    "                label[tf_classes] = 1 ## 폴더 순서대로 라벨링\n",
    "        \n",
    "                for i in range(len(mfcc)) :\n",
    "                    Y_label.append(label)\n",
    "                    \n",
    "        tf_classes = tf_classes + 1 ## 클래스번호 부여\n",
    "\n",
    "    print(\"X_data : \", np.shape(X_data))\n",
    "    print(\"Y_label : \", np.shape(Y_label))\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(np.array(X_data), np.array(Y_label), test_size = 0.2, stratify = np.array(Y_label))\n",
    "    xy = (X_train, X_test, Y_train, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "33021024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Foldername :  강은기 - 19 파일\n",
      "Foldername :  강은서 - 19 파일\n",
      "Foldername :  김나리 - 19 파일\n",
      "Foldername :  김엄지 - 19 파일\n",
      "Foldername :  김용준 - 19 파일\n",
      "Foldername :  윤동준 - 19 파일\n",
      "Foldername :  이성민 - 19 파일\n",
      "Foldername :  이재빈 - 19 파일\n",
      "Foldername :  정승화 - 19 파일\n",
      "Foldername :  주다빈 - 19 파일\n",
      "Foldername :  주홍식 - 19 파일\n",
      "X_data :  (46336, 19)\n",
      "Y_label :  (46336, 11)\n",
      "11 개의 클래스!!\n",
      "X_train :  (37068, 19)\n",
      "Y_train :  (37068, 11)\n",
      "X_test :  (9268, 19)\n",
      "Y_test :  (9268, 11)\n",
      "(37068, 19, 1)\n",
      "(9268, 19, 1)\n"
     ]
    }
   ],
   "source": [
    "load_npy(DATA_PATH)\n",
    "\n",
    "print(tf_classes,\"개의 클래스!!\")\n",
    "print(\"X_train : \", np.shape(X_train))\n",
    "print(\"Y_train : \", np.shape(Y_train))\n",
    "print(\"X_test : \", np.shape(X_test))\n",
    "print(\"Y_test : \", np.shape(Y_test))\n",
    "\n",
    "X_train = np.expand_dims(X_train, -1) # 차수 늘리기 >> Conv1D는 3개의 텐서가 필요 \n",
    "X_test = np.expand_dims(X_test, -1)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "babd29ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(patience = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3eb6583",
   "metadata": {},
   "outputs": [],
   "source": [
    "datalist1 = [\"./test_mfcc/강은기_19.npy\", \"./test_mfcc/강은서_19.npy\", \"./test_mfcc/김나리_19.npy\",\n",
    "             \"./test_mfcc/김엄지_19.npy\", \"./test_mfcc/김용준_19.npy\", \"./test_mfcc/윤동준_19.npy\",\n",
    "            \"./test_mfcc/이성민_19.npy\", \"./test_mfcc/이재빈_19.npy\", \"./test_mfcc/정승화_19.npy\",\n",
    "            \"./test_mfcc/주다빈_19.npy\", \"./test_mfcc/주홍식_19.npy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2359bf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 19, 1)]           0         \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 7, 128)            640       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 7, 128)           512       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " activation (Activation)     (None, 7, 128)            0         \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 4, 128)           0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 4, 128)            65664     \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 4, 128)           512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 4, 128)            0         \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 2, 128)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 2, 256)            98560     \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 2, 256)           1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 2, 256)            0         \n",
      "                                                                 \n",
      " max_pooling1d_2 (MaxPooling  (None, 1, 256)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_3 (Conv1D)           (None, 1, 512)            262656    \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 1, 512)           2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 1, 512)            0         \n",
      "                                                                 \n",
      " max_pooling1d_3 (MaxPooling  (None, 1, 512)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 431,616\n",
      "Trainable params: 429,568\n",
      "Non-trainable params: 2,048\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_layer = tf.keras.Input(X_train[0].shape)\n",
    "conv_top = tf.keras.layers.Conv1D(128,\n",
    "                                   kernel_size = 4,\n",
    "                                   strides = 3,\n",
    "                                   padding = 'same',\n",
    "                                   kernel_initializer = 'glorot_uniform',\n",
    "                                   kernel_regularizer = tf.keras.regularizers.L2(l=0.0001))(input_layer)\n",
    "conv_top = BatchNormalization()(conv_top)\n",
    "conv_top = tf.keras.layers.Activation('relu')(conv_top)\n",
    "conv_top = tf.keras.layers.MaxPool1D(pool_size = 2,\n",
    "                                     strides = None,\n",
    "                                     padding = 'same')(conv_top)\n",
    "    \n",
    "conv_top = tf.keras.layers.Conv1D(128, kernel_size = 4, \n",
    "                                   strides = 1,\n",
    "                                   padding = 'same',\n",
    "                                   kernel_initializer = 'glorot_uniform',\n",
    "                                   kernel_regularizer = tf.keras.regularizers.L2(l=0.0001))(conv_top)\n",
    "conv_top = BatchNormalization()(conv_top)\n",
    "conv_top = tf.keras.layers.Activation('relu')(conv_top)\n",
    "conv_top = tf.keras.layers.MaxPool1D(pool_size = 2, \n",
    "                                     strides = None,\n",
    "                                     padding = 'same')(conv_top)\n",
    "    \n",
    "conv_top = tf.keras.layers.Conv1D(256, kernel_size = 3,\n",
    "                                   strides = 1,\n",
    "                                   padding = 'same',\n",
    "                                   kernel_initializer = 'glorot_uniform',\n",
    "                                   kernel_regularizer = tf.keras.regularizers.L2(l=0.0001))(conv_top)\n",
    "conv_top = BatchNormalization()(conv_top)\n",
    "conv_top = tf.keras.layers.Activation('relu')(conv_top)\n",
    "conv_top = tf.keras.layers.MaxPool1D(pool_size = 2, \n",
    "                                     strides = None,\n",
    "                                     padding = 'same')(conv_top)\n",
    "    \n",
    "conv_top = tf.keras.layers.Conv1D(512, kernel_size = 2, \n",
    "                                   strides = 1,\n",
    "                                   padding = 'same',\n",
    "                                   kernel_initializer = 'glorot_uniform',\n",
    "                                   kernel_regularizer = tf.keras.regularizers.L2(l=0.0001))(conv_top)\n",
    "conv_top = BatchNormalization()(conv_top)\n",
    "conv_top = tf.keras.layers.Activation('relu')(conv_top)\n",
    "conv_top = tf.keras.layers.MaxPool1D(pool_size = 2, strides = None, padding = 'same')(conv_top)\n",
    "\n",
    "conv_top = tf.keras.models.Model(input_layer, conv_top)\n",
    "conv_top.summary()\n",
    "\n",
    "conv_top.compile(loss = 'categorical_crossentropy',\n",
    "              optimizer = 'adam',             \n",
    "             metrics = ['accuracy'])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ebced1bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " model (Functional)          (None, 1, 512)            431616    \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                32832     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 11)                715       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 465,163\n",
      "Trainable params: 33,547\n",
      "Non-trainable params: 431,616\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "top_model = Sequential()\n",
    "top_model.add(conv_top)\n",
    "top_model.add(Flatten())\n",
    "top_model.add(Dense(64, activation = 'relu'))\n",
    "top_model.add(Dense(tf_classes, activation = 'softmax'))\n",
    "top_model.summary()\n",
    "\n",
    "top_model.compile(loss = 'categorical_crossentropy',\n",
    "              optimizer = 'adam',             \n",
    "             metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c459ff6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "304/304 [==============================] - 6s 16ms/step - loss: 0.6612 - accuracy: 0.7865 - val_loss: 0.7966 - val_accuracy: 0.7562\n",
      "Epoch 2/100\n",
      "304/304 [==============================] - 5s 15ms/step - loss: 0.4973 - accuracy: 0.8435 - val_loss: 0.5474 - val_accuracy: 0.8269\n",
      "Epoch 3/100\n",
      "304/304 [==============================] - 5s 15ms/step - loss: 0.4415 - accuracy: 0.8617 - val_loss: 0.4974 - val_accuracy: 0.8445\n",
      "Epoch 4/100\n",
      "304/304 [==============================] - 5s 16ms/step - loss: 0.4055 - accuracy: 0.8761 - val_loss: 0.5803 - val_accuracy: 0.8221\n",
      "Epoch 5/100\n",
      "304/304 [==============================] - 5s 17ms/step - loss: 0.3751 - accuracy: 0.8879 - val_loss: 0.4602 - val_accuracy: 0.8653\n",
      "Epoch 6/100\n",
      "304/304 [==============================] - 5s 15ms/step - loss: 0.3546 - accuracy: 0.8965 - val_loss: 0.4158 - val_accuracy: 0.8810\n",
      "Epoch 7/100\n",
      "304/304 [==============================] - 5s 16ms/step - loss: 0.3385 - accuracy: 0.8992 - val_loss: 0.4368 - val_accuracy: 0.8774\n",
      "Epoch 8/100\n",
      "304/304 [==============================] - 5s 15ms/step - loss: 0.3152 - accuracy: 0.9110 - val_loss: 0.4096 - val_accuracy: 0.8840\n",
      "Epoch 9/100\n",
      "304/304 [==============================] - 5s 16ms/step - loss: 0.2985 - accuracy: 0.9169 - val_loss: 0.4003 - val_accuracy: 0.8890\n",
      "Epoch 10/100\n",
      "304/304 [==============================] - 5s 15ms/step - loss: 0.2839 - accuracy: 0.9231 - val_loss: 0.4558 - val_accuracy: 0.8805\n",
      "Epoch 11/100\n",
      "304/304 [==============================] - 5s 16ms/step - loss: 0.2775 - accuracy: 0.9258 - val_loss: 0.4210 - val_accuracy: 0.8866\n",
      "Epoch 12/100\n",
      "304/304 [==============================] - 5s 16ms/step - loss: 0.2703 - accuracy: 0.9303 - val_loss: 0.4458 - val_accuracy: 0.8781\n",
      "Epoch 13/100\n",
      "304/304 [==============================] - 5s 16ms/step - loss: 0.2559 - accuracy: 0.9364 - val_loss: 0.4224 - val_accuracy: 0.8903\n",
      "Epoch 14/100\n",
      "304/304 [==============================] - 5s 15ms/step - loss: 0.2525 - accuracy: 0.9372 - val_loss: 0.4153 - val_accuracy: 0.8931\n",
      "Epoch 15/100\n",
      "304/304 [==============================] - 5s 15ms/step - loss: 0.2416 - accuracy: 0.9410 - val_loss: 0.4543 - val_accuracy: 0.8843\n",
      "Epoch 16/100\n",
      "304/304 [==============================] - 5s 15ms/step - loss: 0.2270 - accuracy: 0.9476 - val_loss: 0.4182 - val_accuracy: 0.8968\n",
      "Epoch 17/100\n",
      "304/304 [==============================] - 5s 16ms/step - loss: 0.2351 - accuracy: 0.9438 - val_loss: 0.4258 - val_accuracy: 0.8961\n",
      "Epoch 18/100\n",
      "304/304 [==============================] - 5s 15ms/step - loss: 0.2201 - accuracy: 0.9503 - val_loss: 0.4438 - val_accuracy: 0.8903\n",
      "Epoch 19/100\n",
      "304/304 [==============================] - 4s 14ms/step - loss: 0.2193 - accuracy: 0.9528 - val_loss: 0.4494 - val_accuracy: 0.8868\n",
      "Epoch 20/100\n",
      "304/304 [==============================] - 4s 14ms/step - loss: 0.2175 - accuracy: 0.9540 - val_loss: 0.4530 - val_accuracy: 0.8919\n",
      "Epoch 21/100\n",
      "304/304 [==============================] - 4s 14ms/step - loss: 0.2073 - accuracy: 0.9570 - val_loss: 0.4754 - val_accuracy: 0.8918\n",
      "Epoch 22/100\n",
      "304/304 [==============================] - 4s 13ms/step - loss: 0.2007 - accuracy: 0.9601 - val_loss: 0.4387 - val_accuracy: 0.8986\n",
      "Epoch 23/100\n",
      "304/304 [==============================] - 4s 15ms/step - loss: 0.2058 - accuracy: 0.9587 - val_loss: 0.4855 - val_accuracy: 0.8957\n",
      "Epoch 24/100\n",
      "304/304 [==============================] - 5s 15ms/step - loss: 0.1937 - accuracy: 0.9634 - val_loss: 0.4342 - val_accuracy: 0.9014\n",
      "Epoch 25/100\n",
      "304/304 [==============================] - 5s 15ms/step - loss: 0.1925 - accuracy: 0.9631 - val_loss: 0.4666 - val_accuracy: 0.8967\n",
      "Epoch 26/100\n",
      "304/304 [==============================] - 5s 16ms/step - loss: 0.2012 - accuracy: 0.9606 - val_loss: 0.5806 - val_accuracy: 0.8760\n",
      "Epoch 27/100\n",
      "304/304 [==============================] - 4s 14ms/step - loss: 0.1897 - accuracy: 0.9654 - val_loss: 0.4704 - val_accuracy: 0.9015\n",
      "Epoch 28/100\n",
      "304/304 [==============================] - 4s 15ms/step - loss: 0.1768 - accuracy: 0.9703 - val_loss: 0.4526 - val_accuracy: 0.9029\n",
      "Epoch 29/100\n",
      "304/304 [==============================] - 4s 15ms/step - loss: 0.1886 - accuracy: 0.9648 - val_loss: 0.4973 - val_accuracy: 0.8953\n",
      "Epoch 30/100\n",
      "304/304 [==============================] - 5s 15ms/step - loss: 0.1901 - accuracy: 0.9652 - val_loss: 0.5176 - val_accuracy: 0.8906\n",
      "Epoch 31/100\n",
      "304/304 [==============================] - 5s 17ms/step - loss: 0.1806 - accuracy: 0.9705 - val_loss: 0.5482 - val_accuracy: 0.8881\n",
      "Epoch 32/100\n",
      "304/304 [==============================] - 5s 15ms/step - loss: 0.1856 - accuracy: 0.9683 - val_loss: 0.4732 - val_accuracy: 0.9072\n",
      "Epoch 33/100\n",
      "304/304 [==============================] - 5s 16ms/step - loss: 0.1835 - accuracy: 0.9706 - val_loss: 0.4923 - val_accuracy: 0.8998\n",
      "Epoch 34/100\n",
      "304/304 [==============================] - 5s 15ms/step - loss: 0.1675 - accuracy: 0.9755 - val_loss: 0.4935 - val_accuracy: 0.9004\n",
      "Epoch 35/100\n",
      "304/304 [==============================] - 5s 15ms/step - loss: 0.1773 - accuracy: 0.9717 - val_loss: 0.5047 - val_accuracy: 0.8977\n",
      "Epoch 36/100\n",
      "304/304 [==============================] - 5s 15ms/step - loss: 0.1740 - accuracy: 0.9738 - val_loss: 0.5089 - val_accuracy: 0.8967\n",
      "Epoch 37/100\n",
      "304/304 [==============================] - 5s 15ms/step - loss: 0.1785 - accuracy: 0.9729 - val_loss: 0.5143 - val_accuracy: 0.8971\n",
      "Epoch 38/100\n",
      "304/304 [==============================] - 5s 15ms/step - loss: 0.1625 - accuracy: 0.9774 - val_loss: 0.5423 - val_accuracy: 0.8924\n",
      "Epoch 39/100\n",
      "304/304 [==============================] - 5s 15ms/step - loss: 0.1797 - accuracy: 0.9721 - val_loss: 0.5703 - val_accuracy: 0.8836\n"
     ]
    }
   ],
   "source": [
    "# 모델 구현 시간 체크\n",
    "import time\n",
    "# 시작시간 체크\n",
    "start = time.time()\n",
    "history = top_model.fit(X_train, Y_train, epochs = 100, batch_size = 100, validation_data = (X_test, Y_test), callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cdf4a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 종료 시간 확인\n",
    "end = time.time()\n",
    "# 모델 구동 시간 계산\n",
    "print(f\"모델구동시간 : {end-start} sec.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eecd4803",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.5883 - accuracy: 0.8884\n",
      "1\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4973 - accuracy: 0.8830\n",
      "2\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.2867 - accuracy: 0.7604\n",
      "3\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1071 - accuracy: 0.9957\n",
      "4\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4039 - accuracy: 0.9246\n",
      "5\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.5159 - accuracy: 0.8473\n",
      "6\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 2.2037 - accuracy: 0.5636\n",
      "7\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4493 - accuracy: 0.9412\n",
      "8\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.8029 - accuracy: 0.8448\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list assignment index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19208/1208738765.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mlabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf_classes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m# class의 개수만큼 y_test만드는 과정\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mlabel\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnum\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list assignment index out of range"
     ]
    }
   ],
   "source": [
    "## 사용자 화자인식 테스트\n",
    "\n",
    "num = 0\n",
    "for i in datalist1 :\n",
    "\n",
    "    XX_test = np.load(i)\n",
    "    YY_test = []\n",
    "\n",
    "    label = [0 for i in range(tf_classes)] # class의 개수만큼 y_test만드는 과정\n",
    "    label[num] = 1\n",
    "\n",
    "    for i in range(len(XX_test)) :\n",
    "        YY_test.append(label)\n",
    "\n",
    "    XX_train = np.array(X_train)\n",
    "    XX_test = np.array(XX_test)\n",
    "    YY_train = np.array(Y_train)\n",
    "    YY_test = np.array(YY_test)\n",
    "    print(num)\n",
    "    XX_test = np.expand_dims(XX_test, -1)\n",
    "\n",
    "    top_model.evaluate(XX_test, YY_test)\n",
    "    num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fefdc0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_top.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d1a3e333",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "371/371 [==============================] - 3s 7ms/step - loss: 0.6125 - accuracy: 0.8333 - val_loss: 0.4466 - val_accuracy: 0.8801\n",
      "Epoch 2/100\n",
      "371/371 [==============================] - 2s 6ms/step - loss: 0.4168 - accuracy: 0.8943 - val_loss: 0.4107 - val_accuracy: 0.8913\n",
      "Epoch 3/100\n",
      "371/371 [==============================] - 2s 6ms/step - loss: 0.3836 - accuracy: 0.9038 - val_loss: 0.3947 - val_accuracy: 0.8976\n",
      "Epoch 4/100\n",
      "371/371 [==============================] - 2s 6ms/step - loss: 0.3602 - accuracy: 0.9105 - val_loss: 0.3846 - val_accuracy: 0.9005\n",
      "Epoch 5/100\n",
      "371/371 [==============================] - 2s 5ms/step - loss: 0.3456 - accuracy: 0.9163 - val_loss: 0.3851 - val_accuracy: 0.9015\n",
      "Epoch 6/100\n",
      "371/371 [==============================] - 2s 6ms/step - loss: 0.3325 - accuracy: 0.9205 - val_loss: 0.3754 - val_accuracy: 0.9031\n",
      "Epoch 7/100\n",
      "371/371 [==============================] - 2s 6ms/step - loss: 0.3195 - accuracy: 0.9247 - val_loss: 0.3735 - val_accuracy: 0.9058\n",
      "Epoch 8/100\n",
      "371/371 [==============================] - 3s 7ms/step - loss: 0.3101 - accuracy: 0.9281 - val_loss: 0.3688 - val_accuracy: 0.9107\n",
      "Epoch 9/100\n",
      "371/371 [==============================] - 2s 6ms/step - loss: 0.3001 - accuracy: 0.9312 - val_loss: 0.3711 - val_accuracy: 0.9061\n",
      "Epoch 10/100\n",
      "371/371 [==============================] - 2s 6ms/step - loss: 0.2907 - accuracy: 0.9345 - val_loss: 0.3705 - val_accuracy: 0.9050\n",
      "Epoch 11/100\n",
      "371/371 [==============================] - 2s 5ms/step - loss: 0.2857 - accuracy: 0.9370 - val_loss: 0.3679 - val_accuracy: 0.9095\n",
      "Epoch 12/100\n",
      "371/371 [==============================] - 2s 6ms/step - loss: 0.2753 - accuracy: 0.9396 - val_loss: 0.3752 - val_accuracy: 0.9099\n",
      "Epoch 13/100\n",
      "371/371 [==============================] - 2s 6ms/step - loss: 0.2697 - accuracy: 0.9421 - val_loss: 0.3805 - val_accuracy: 0.9081\n",
      "Epoch 14/100\n",
      "371/371 [==============================] - 2s 6ms/step - loss: 0.2626 - accuracy: 0.9450 - val_loss: 0.3723 - val_accuracy: 0.9075\n",
      "Epoch 15/100\n",
      "371/371 [==============================] - 2s 6ms/step - loss: 0.2565 - accuracy: 0.9472 - val_loss: 0.3780 - val_accuracy: 0.9049\n",
      "Epoch 16/100\n",
      "371/371 [==============================] - 2s 6ms/step - loss: 0.2500 - accuracy: 0.9486 - val_loss: 0.3817 - val_accuracy: 0.9077\n",
      "Epoch 17/100\n",
      "371/371 [==============================] - 2s 6ms/step - loss: 0.2441 - accuracy: 0.9519 - val_loss: 0.3821 - val_accuracy: 0.9094\n",
      "Epoch 18/100\n",
      "371/371 [==============================] - 2s 5ms/step - loss: 0.2382 - accuracy: 0.9546 - val_loss: 0.3776 - val_accuracy: 0.9102\n",
      "Epoch 19/100\n",
      "371/371 [==============================] - 2s 5ms/step - loss: 0.2336 - accuracy: 0.9554 - val_loss: 0.3901 - val_accuracy: 0.9084\n",
      "Epoch 20/100\n",
      "371/371 [==============================] - 2s 6ms/step - loss: 0.2283 - accuracy: 0.9568 - val_loss: 0.3865 - val_accuracy: 0.9093\n",
      "Epoch 21/100\n",
      "371/371 [==============================] - 2s 5ms/step - loss: 0.2235 - accuracy: 0.9586 - val_loss: 0.4015 - val_accuracy: 0.9071\n",
      "Epoch 22/100\n",
      "371/371 [==============================] - 2s 6ms/step - loss: 0.2183 - accuracy: 0.9605 - val_loss: 0.4169 - val_accuracy: 0.9044\n",
      "Epoch 23/100\n",
      "371/371 [==============================] - 3s 7ms/step - loss: 0.2147 - accuracy: 0.9609 - val_loss: 0.4142 - val_accuracy: 0.9020\n",
      "Epoch 24/100\n",
      "371/371 [==============================] - 2s 6ms/step - loss: 0.2110 - accuracy: 0.9627 - val_loss: 0.4057 - val_accuracy: 0.9063\n",
      "Epoch 25/100\n",
      "371/371 [==============================] - 2s 6ms/step - loss: 0.2062 - accuracy: 0.9650 - val_loss: 0.4055 - val_accuracy: 0.9088\n",
      "Epoch 26/100\n",
      "371/371 [==============================] - 2s 6ms/step - loss: 0.2018 - accuracy: 0.9671 - val_loss: 0.4184 - val_accuracy: 0.9052\n",
      "Epoch 27/100\n",
      "371/371 [==============================] - 2s 7ms/step - loss: 0.1968 - accuracy: 0.9685 - val_loss: 0.4154 - val_accuracy: 0.9098\n",
      "Epoch 28/100\n",
      "371/371 [==============================] - 2s 6ms/step - loss: 0.1926 - accuracy: 0.9714 - val_loss: 0.4229 - val_accuracy: 0.9062\n",
      "Epoch 29/100\n",
      "371/371 [==============================] - 2s 6ms/step - loss: 0.1894 - accuracy: 0.9712 - val_loss: 0.4273 - val_accuracy: 0.9056\n",
      "Epoch 30/100\n",
      "371/371 [==============================] - 2s 5ms/step - loss: 0.1867 - accuracy: 0.9727 - val_loss: 0.4430 - val_accuracy: 0.9041\n",
      "Epoch 31/100\n",
      "371/371 [==============================] - 2s 6ms/step - loss: 0.1833 - accuracy: 0.9741 - val_loss: 0.4355 - val_accuracy: 0.9043\n",
      "Epoch 32/100\n",
      "371/371 [==============================] - 2s 6ms/step - loss: 0.1793 - accuracy: 0.9759 - val_loss: 0.4335 - val_accuracy: 0.9068\n",
      "Epoch 33/100\n",
      "371/371 [==============================] - 2s 6ms/step - loss: 0.1757 - accuracy: 0.9770 - val_loss: 0.4407 - val_accuracy: 0.9061\n",
      "Epoch 34/100\n",
      "371/371 [==============================] - 2s 6ms/step - loss: 0.1724 - accuracy: 0.9787 - val_loss: 0.4511 - val_accuracy: 0.9047\n",
      "Epoch 35/100\n",
      "371/371 [==============================] - 2s 6ms/step - loss: 0.1700 - accuracy: 0.9786 - val_loss: 0.4475 - val_accuracy: 0.9062\n",
      "Epoch 36/100\n",
      "371/371 [==============================] - 3s 8ms/step - loss: 0.1665 - accuracy: 0.9805 - val_loss: 0.4728 - val_accuracy: 0.9022\n",
      "Epoch 37/100\n",
      "371/371 [==============================] - 3s 8ms/step - loss: 0.1650 - accuracy: 0.9814 - val_loss: 0.4722 - val_accuracy: 0.9042\n",
      "Epoch 38/100\n",
      "371/371 [==============================] - 3s 7ms/step - loss: 0.1618 - accuracy: 0.9817 - val_loss: 0.4702 - val_accuracy: 0.9053\n",
      "Epoch 39/100\n",
      "371/371 [==============================] - 2s 6ms/step - loss: 0.1598 - accuracy: 0.9820 - val_loss: 0.4697 - val_accuracy: 0.9062\n",
      "Epoch 40/100\n",
      "371/371 [==============================] - 2s 6ms/step - loss: 0.1577 - accuracy: 0.9826 - val_loss: 0.4729 - val_accuracy: 0.9081\n",
      "Epoch 41/100\n",
      "371/371 [==============================] - 2s 6ms/step - loss: 0.1523 - accuracy: 0.9852 - val_loss: 0.4974 - val_accuracy: 0.9014\n"
     ]
    }
   ],
   "source": [
    "# 모델 구현 시간 체크\n",
    "import time\n",
    "# 시작시간 체크\n",
    "start = time.time()\n",
    "history = top_model.fit(X_train, Y_train, epochs = 100, batch_size = 100, validation_data = (X_test, Y_test), callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bb56938c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.9053 - accuracy: 0.8595\n",
      "1\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.8411 - accuracy: 0.8538\n",
      "2\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.6538 - accuracy: 0.7552\n",
      "3\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.1032 - accuracy: 1.0000\n",
      "4\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4465 - accuracy: 0.9365\n",
      "5\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.8431 - accuracy: 0.8397\n",
      "6\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 2.3311 - accuracy: 0.6424\n",
      "7\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.9966 - accuracy: 0.8706\n",
      "8\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.8964 - accuracy: 0.8333\n",
      "9\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.8423 - accuracy: 0.8358\n",
      "10\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5979 - accuracy: 0.8539\n"
     ]
    }
   ],
   "source": [
    "## 사용자 화자인식 테스트\n",
    "\n",
    "num = 0\n",
    "for i in datalist1 :\n",
    "\n",
    "    XX_test = np.load(i)\n",
    "    YY_test = []\n",
    "\n",
    "    label = [0 for i in range(tf_classes)] # class의 개수만큼 y_test만드는 과정\n",
    "    label[num] = 1\n",
    "\n",
    "    for i in range(len(XX_test)) :\n",
    "        YY_test.append(label)\n",
    "\n",
    "    XX_train = np.array(X_train)\n",
    "    XX_test = np.array(XX_test)\n",
    "    YY_train = np.array(Y_train)\n",
    "    YY_test = np.array(YY_test)\n",
    "    print(num)\n",
    "    XX_test = np.expand_dims(XX_test, -1)\n",
    "\n",
    "    top_model.evaluate(XX_test, YY_test)\n",
    "    num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "2c40fb4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(\"./모델/model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "bb0ab91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"./모델/model.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
